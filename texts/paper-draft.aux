\relax 
\emailauthor{fc@di.uevora.pt}{Francisco Coelho}
\emailauthor{jpn@di.fc.ul.pt}{João Pedro Neto}
\citation{mendes2005adaptive}
\citation{davidson1999method}
\citation{sanchez2009obtaining}
\citation{csefalvayova2010use}
\citation{chan2011modeling}
\citation{galvez2012iterative}
\citation{chan2012development}
\citation{garcia2013hybrid}
\citation{barricelli1962numerical}
\citation{holland1975adaptation}
\reset@newl@bel
\newacro{GA}[GA]{Genetic algorithms}
\newacro{rmse}[error]{root-mean-square error}
\newacro{GAPoly}[\sc  GAPoly]{Genetic Algorithms for Polynomials}
\Newlabel{ue}{a}
\Newlabel{fcul}{b}
\Newlabel{labmag}{c}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\undonewlabel{acro:GA}
\newlabel{acro:GA}{{1}{1}}
\acronymused{GA}
\citation{koza1992genetic}
\citation{bengio2013representation,bengio2009learning}
\citation{tarlowstochastic}
\citation{maertens2006genetic,yu2008optimal,wu2009novel}
\citation{hofwing2011optimal,cetisli2011polynomial}
\acronymused{GA}
\acronymused{GA}
\acronymused{GA}
\acronymused{GA}
\undonewlabel{acro:rmse}
\newlabel{acro:rmse}{{1}{2}}
\acronymused{rmse}
\undonewlabel{acro:GAPoly}
\newlabel{acro:GAPoly}{{1}{2}}
\acronymused{GAPoly}
\@writefile{toc}{\contentsline {section}{\numberline {2}Genetic Algorithms for Polynomials}{2}}
\acronymused{GA}
\acronymused{rmse}
\acronymused{rmse}
\newlabel{eq:rmse}{{1}{3}}
\acronymused{rmse}
\acronymused{GA}
\acronymused{GAPoly}
\acronymused{rmse}
\acronymused{GA}
\acronymused{rmse}
\acronymused{rmse}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \ac {GAPoly} uses linear regression to find monomial coefficients that minimize the \ac {rmse} over a dataset and \acp {GA} to explore the space of polynomials. At exit the \ac {rmse} of the fittest instance is bounded by $\epsilon $.}}{4}}
\newlabel{alg:gapoly}{{1}{4}}
\acronymused{GA}
\acronymused{GA}
\acronymused{GA}
\acronymused{rmse}
\acronymused{GA}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Polinomial Encoding}{4}}
\newlabel{subs:polynomial.encoding}{{2.1}{4}}
\acronymused{rmse}
\citation{willighage2012genalg}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Cost Function}{5}}
\newlabel{subs:cost.function}{{2.2}{5}}
\acronymused{rmse}
\acronymused{rmse}
\acronymused{rmse}
\newlabel{eq:rmse-reg}{{2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Genetic Operators}{5}}
\citation{R}
\citation{Meyer12}
\citation{Therneau13}
\citation{Hothorn06,Strobl07,Strobl08}
\citation{Liaw02}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Error distribution by regularization exponent for the Abalone dataset.}}{6}}
\newlabel{Abalone_dataset_lambdas}{{1}{6}}
\newlabel{Auto-MPG_dataset_lambdas}{{1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Results}{6}}
\acronymused{GAPoly}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces results for Artificial dataset \emph  {must} highlight method \#1: GAPoly}}{7}}
\newlabel{artificial_dataset1_lambda1.0}{{2}{7}}
\acronymused{rmse}
\acronymused{GAPoly}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces results for Housing, Abalone, Auto MPG and Kinematics datasets. Methods are: 1: \ac {GAPoly}, 2: Random Forests 3: Linear Regression, 4: SVM, 5: RPART and 6: CI.Tree}}{8}}
\acronymused{GAPoly}
\newlabel{Housing_dataset_lambda0.8_25runs}{{3}{8}}
\newlabel{Abalone_dataset_lambda0.8_25runs}{{3}{8}}
\newlabel{Auto-Mpg_dataset_lambda0.8_25runs}{{3}{8}}
\newlabel{Kinematics300_lambda0.8_25runs}{{3}{8}}
\acronymused{GAPoly}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Error progress for Abalone dataset (population $200$)}}{9}}
\newlabel{Abalone_fitnessProgress}{{4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Convergence speed}{9}}
\acronymused{GA}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{9}}
\acronymused{GAPoly}
\acronymused{GAPoly}
\bibstyle{plain}
\bibdata{fullbib}
\bibcite{barricelli1962numerical}{{1}{}{{}}{{}}}
\bibcite{bengio2009learning}{{2}{}{{}}{{}}}
\bibcite{bengio2013representation}{{3}{}{{}}{{}}}
\bibcite{cetisli2011polynomial}{{4}{}{{}}{{}}}
\bibcite{chan2011modeling}{{5}{}{{}}{{}}}
\bibcite{chan2012development}{{6}{}{{}}{{}}}
\bibcite{csefalvayova2010use}{{7}{}{{}}{{}}}
\bibcite{davidson1999method}{{8}{}{{}}{{}}}
\bibcite{galvez2012iterative}{{9}{}{{}}{{}}}
\bibcite{garcia2013hybrid}{{10}{}{{}}{{}}}
\bibcite{hofwing2011optimal}{{11}{}{{}}{{}}}
\bibcite{holland1975adaptation}{{12}{}{{}}{{}}}
\bibcite{Hothorn06}{{13}{}{{}}{{}}}
\bibcite{koza1992genetic}{{14}{}{{}}{{}}}
\bibcite{Liaw02}{{15}{}{{}}{{}}}
\bibcite{maertens2006genetic}{{16}{}{{}}{{}}}
\bibcite{mendes2005adaptive}{{17}{}{{}}{{}}}
\bibcite{Meyer12}{{18}{}{{}}{{}}}
\bibcite{R}{{19}{}{{}}{{}}}
\bibcite{sanchez2009obtaining}{{20}{}{{}}{{}}}
\bibcite{Strobl08}{{21}{}{{}}{{}}}
\bibcite{Strobl07}{{22}{}{{}}{{}}}
\bibcite{tarlowstochastic}{{23}{}{{}}{{}}}
\bibcite{Therneau13}{{24}{}{{}}{{}}}
\bibcite{wu2009novel}{{25}{}{{}}{{}}}
\bibcite{yu2008optimal}{{26}{}{{}}{{}}}
\bibcite{willighage2012genalg}{{27}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
